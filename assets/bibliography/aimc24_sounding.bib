@inproceedings{cotton_sounding_2024,
	title = {Sounding out extra-normal AI voice: Non-normative musical engagements with normative AI voice and speech technologies},
	abstract = {How do we challenge the norms of AI voice technologies? What would be a non-normative approach in finding novel artistic possibilities of speech synthesis and text-to-speech with Deep Learning? This paper delves into SpeechBrain, OpenAI and CoquiTTS voice and speech models with the perspective of an experimental vocal practitioner. An exploratory Research-through-Design process guided an engagement with pre-trained speech synthesis models to reveal their musical affordances in an experimental vocal practice. We recorded this engagement with voice and speech Deep Learning technologies using auto-ethnography, a novel and recent methodology in Human-Computer Interaction. Our position in this paper actively subverts the normative function of these models, provoking nonsensical AI-mediation of human vocality. Emerging from a sense-making process of poetic AI nonsense, we uncover the generative potential of non-normative usage of normative speech recognition and synthesis models. We contribute with insights about the affordances of Research-through-Design to inform artistic processes in working with AI models; how AI-mediations reform understandings of human vocality; and artistic perspectives and practice as knowledge-creation mechanisms for working with technology.},
	language = {en},
	booktitle = {AIMC 2024},
	author = {Cotton, Kelsey and Tatar, Kƒ±van√ß},
	month = aug,
	year = {2024},
	url = {https://aimc2024.pubpub.org/pub/extranormal-aivoice/release/1}
}
@inproceedings{erenCoquiTTS2021,
  title = {Coqui {{TTS}}},
  author = {Eren, G√∂lge and {The Coqui TTS Team}},
  date = {2021-01},
  doi = {10.5281/zenodo.6334862},
  url = {https://github.com/coqui-ai/TTS},
  urldate = {2024-08-08},
  abstract = {üê∏üí¨ - a deep learning toolkit for Text-to-Speech, battle-tested in research and production},
  version = {1.4}
}
@inproceedings{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and Fran√ßois Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}
@inproceedings{radford,
  title = {Robust {{Speech Recognition}} via {{Large-Scale Weak Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  year = {2022},
  eprint = {2212.04356},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url = {http://arxiv.org/abs/2212.04356},
}