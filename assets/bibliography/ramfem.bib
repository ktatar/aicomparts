@inproceedings{bisig_raw_2021,
	title = {Raw Music from Free Movements: Early Experiments in Using Machine Learning to Create Raw Audio from Dance Movements},
	abstract = {Raw Music from Free Movements is a deep learning architecture that translates pose sequences into audio waveforms. The architecture combines a sequence-to-sequence model generating audio encodings and an adversarial autoencoder that generates raw audio from audio encodings. Experiments have been conducted with two datasets: a dancer improvising freely to a given music, and music created through simple movement soniﬁcation. The paper presents preliminary results. These will hopefully lead closer towards a model which can learn from the creative decisions a dancer makes when translating music into movement and then follow these decisions reversely for the purpose of generating music from movement.},
	language = {en},
	booktitle = {Proceedings of the 2nd AI Music Creativity Conference (AIMC 2021)},
	author = {Bisig, Daniel and Tatar, Kıvanç},
	year = {2021},
	pages = {11},
}