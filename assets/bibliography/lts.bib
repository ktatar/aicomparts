@article{tatar_latent_2020,
	title = {Latent Timbre Synthesis},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-020-05424-2},
	doi = {10.1007/s00521-020-05424-2},
	abstract = {We present the Latent Timbre Synthesis, a new audio synthesis method using deep learning. The synthesis method allows composers and sound designers to interpolate and extrapolate between the timbre of multiple sounds using the latent space of audio frames. We provide the details of two Variational Autoencoder architectures for the Latent Timbre Synthesis and compare their advantages and drawbacks. The implementation includes a fully working application with a graphical user interface, called interpolate\_two, which enables practitioners to generate timbres between two audio excerpts of their selection using interpolation and extrapolation in the latent space of audio frames. Our implementation is open source, and we aim to improve the accessibility of this technology by providing a guide for users with any technical background. Our study includes a qualitative analysis where nine composers evaluated the Latent Timbre Synthesis and the interpolate\_two application within their practices.},
	language = {en},
	urldate = {2020-11-09},
	journal = {Neural Computing and Applications},
	author = {Tatar, Kıvanç and Bisig, Daniel and Pasquier, Philippe},
	month = oct,
	year = {2020},
}
