<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Raw Audio VAE | AI in Computational Arts, Music, and Games </title> <meta name="author" content="Kıvanç Tatar"> <meta name="description" content="Sound Design Strategies for Latent Audio Space Explorations Using Deep Learning Architectures"> <meta name="keywords" content="Machine Learning, Artificial Intelligence, Computational Arts, Music, Video Games, Computational Creativity, Musical AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.aicomparts.com//projects/2023-rawaudio/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Raw Audio VAE",
            "description": "Sound Design Strategies for Latent Audio Space Explorations Using Deep Learning Architectures",
            "published": "October 20, 2020",
            "authors": [
              
              {
                "author": "Kıvanç Tatar",
                "authorURL": "https://www.kivanctatar.com",
                "affiliations": [
                  {
                    "name": "Chalmers University of Technology",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Kelsey Cotton",
                "authorURL": "https://www.kelseycotton.com",
                "affiliations": [
                  {
                    "name": "Chalmers University of Technology",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Daniel Bisig",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Zurich University of the Arts",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> AI in Computational Arts, Music, and Games </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/about/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Raw Audio VAE</h1> <p>Sound Design Strategies for Latent Audio Space Explorations Using Deep Learning Architectures</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#description">Description</a></li> <li class="toc-entry toc-h2"><a href="#architecture">Architecture</a></li> <li class="toc-entry toc-h2"><a href="#examples">Examples</a></li> <li class="toc-entry toc-h2"> <a href="#resources">Resources</a> <ul> <li class="toc-entry toc-h3"><a href="#code">Code</a></li> <li class="toc-entry toc-h3"><a href="#artworks">Artworks</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#acknowledgements">Acknowledgements</a></li> </ul> </nav> </d-contents> <h2 id="description">Description</h2> <p>The research in Deep Learning applications in sound and music computing have gathered an interest in the recent years; however, there is still a missing link between these new technologies and on how they can be incorporated into real-world artistic practices. In this work, we explore a well-known Deep Learning architecture called Variational Autoencoders (VAEs). These architectures have been used in many areas for generating latent spaces where data points are organized so that similar data points locate closer to each other. Previously, VAEs have been used for generating latent timbre spaces or latent spaces of symbolic muic excepts. Applying VAE to audio features of timbre reuires a vocoder to transform the timbre generated by the network to an audio signal, which is computationally expensive. In this work<d-cite key="tatar_sound_2023"></d-cite>, we apply VAEs to raw audio data directly while bypassing audio feature extraction. This approach allows the practitioners to use any audio recording while giving flexibility and control over the aesthetics through dataset curation. The lower computation time in audio signal generation allows the raw audio approach to be incorporated into real-time applications. In this work, we propose three strategies to explore latent spaces of audio and timbre for sound design applications. By doing so, our aim is to initiate a conversation on artistic approaches and strategies to utilize latent audio spaces in sound and music practices.</p> <h2 id="architecture">Architecture</h2> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/smc-2023-network-480.webp 480w,/assets/img/publication_preview/smc-2023-network-800.webp 800w,/assets/img/publication_preview/smc-2023-network-1400.webp 1400w,/assets/img/publication_preview/smc-2023-network-1800.webp 1800w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/publication_preview/smc-2023-network.jpg" width="100%" height="auto" title="The Deep Learning architecture in Raw Music From Free Movements" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> The Deep Learning architecture in Raw Audio VAE. </div> <div class="fake-img l-page-outset"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/smc-2023-interpolation-480.webp 480w,/assets/img/smc-2023-interpolation-800.webp 800w,/assets/img/smc-2023-interpolation-1400.webp 1400w,/assets/img/smc-2023-interpolation-1800.webp 1800w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/smc-2023-interpolation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Latent Space Visualisation" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Interpolation Strategies </div> <h2 id="examples">Examples</h2> <p>Two different datasets were employed for training, named improvisation dataset and sonification dataset. The improvisation dataset consists of pose sequences and audio that have been recorded while a dancer was freely improvising to a given music. The dancer is an expert with a specialisation in contemporary dance and improvisation. The music consists of short excerpts of royalty free music including experimental electronic music, free jazz, and contemporary classic. The pose sequences have been acquired using the markerless motion capture system (The Captury ) in the iLab at MotionBank, University for Applied Research, Mainz. The recording is 10 minutes in length which corresponds to a sequence of 30000 poses. Each pose consists of 29 joints whose relative orientations are represented by quaternions.</p> <p>The sonification dataset contains the same pose sequences as the improvisation dataset. The audio of this dataset was created afterwards, through sonification, employing a very simple sound synthesis consisting of two sine oscillators controlled by the dancer’s hands. The frequency and amplitude of each oscillator are proportional to the height and velocity of the corresponding hand, respectively. The authors created this dataset to verify the performance of RAMFEM.</p> <h2 id="resources">Resources</h2> <h3 id="code">Code</h3> <p><i class="fa-brands fa-github"></i> <a>https://github.com/ktatar/rawaudiovae</a></p> <h3 id="artworks">Artworks</h3> <p>The artwork titled <a href="https://kivanctatar.com/Coding-the-Latent" rel="external nofollow noopener" target="_blank">Coding the Latent</a> by <a href="https://kivanctatar.com/" rel="external nofollow noopener" target="_blank">Kıvanç Tatar</a> uses three interpolation strategies presented in this paper, within a live coding environment, performed at Kubus, ZKM, Karlsruhe.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>This work was partially supported by the Wallenberg AI, Autonomous Systems and Software Program – Humanities and Society (WASP-HS) funded by the Marianne and Marcus Wallenberg Foundation and the Marcus and Amalia Wallenberg Foundation. Additionally, this research was previously supported by the Swiss National Science Foundation, and Canada Council for the Arts.</p> <div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logos/wasphs-480.webp 480w,/assets/img/logos/wasphs-800.webp 800w,/assets/img/logos/wasphs-1400.webp 1400w,/assets/img/logos/wasphs-1800.webp 1800w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/logos/wasphs.png" width="100%" height="auto" title="wasp-hs logo" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logos/snf-480.webp 480w,/assets/img/logos/snf-800.webp 800w,/assets/img/logos/snf-1400.webp 1400w,/assets/img/logos/snf-1800.webp 1800w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/logos/snf.png" width="100%" height="auto" title="Swiss National Science Foundation logo" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logos/cca-480.webp 480w,/assets/img/logos/cca-800.webp 800w,/assets/img/logos/cca-1400.webp 1400w,/assets/img/logos/cca-1800.webp 1800w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/logos/cca.jpg" width="100%" height="auto" title="Canada Council for the Arts" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/rawaudio.bib"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 Kıvanç Tatar. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>